\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{graphicx}
\usepackage{tcolorbox}

\usetheme{metropolis} % Tema moderno e minimale


\title{Identificazione e disambiguazione della costruzione NPN con BERT}
\subtitle{Caso studio di Scivetti e Schneider sulla costruzione inglese} % <-- sottotitolo
\author{Corso di Semantica a.a. 2025/2026}
\institute{Università di Bologna}
\date{18 Novembre 2025}
\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Indice}
  \tableofcontents
\end{frame}

\section{La costruzione NPN}

\begin{frame}{Cos'è la costruzione NPN}
  La costruzione NPN è stata ampiamente studiata in inglese da una prospettiva costruzionista,
  in particolare da Jackendoff (2008) e Sommerer \& Baumann (2021).

  \begin{tcolorbox}[colback=white, colframe=black, arc=4mm, boxrule=0.8pt, center title, title=Construction Schema]
    \[
      Noun_1 \; \text{Preposition} \; Noun_2
    \]
  \end{tcolorbox}

  I due nomi nella costruzione devono avere forma identica, anche per la declinazione del numero.
  La costruzione non ammette nomi accompagnati da determinati.
\end{frame}

\begin{frame}{Cos'è la costruzione NPN}
  La costruzione può comparire in diverse posizioni sintattiche, ad esempio come modificatore avverbiale o come modificatore nominale.

  \begin{exampleblock}{Esempi}
    \begin{itemize}
      \item \textit{I need you to get this \textbf{word for word.}} 
      \\
      \hfill (modificatore avverbiale)
      \item \textit{There is a rebellious quality to your \textbf{day to day}
responses which have not gone unnoticed.} \hfill (modificatore nominale)
    \end{itemize}
  \end{exampleblock}

\end{frame}

\begin{frame}{Significato e funzione}

Significati delle costruzioni NPN istanziate da \textit{to}

  \begin{block}{SUCCESSION}
    Testo del blocco esplicativo.
  \end{block}

  \begin{block}{JUXTAPOSITION}
    Testo del blocco esplicativo.
  \end{block}

\end{frame}


\section{Il Dataset}

\begin{frame}{Il Dataset}
  \begin{itemize}
    \item estrazione da COCA
    \item Eliminazione dei casi PNPN
    \item Identificazione dei distrattori
    \item Annotazione per tutte le istanze delle etichette semantiche 
  \end{itemize}
\end{frame}

\begin{frame}{Affidabilità dell'annotazione}

\textbf{Doppia annotazione}
\begin{itemize}
    \item Annotato \textbf{~25\%} del dataset
    \item Accordo grezzo: \textbf{84\%}
    \item Cohen's kappa: \textbf{0.754} (accordo forte)
\end{itemize}

\vspace{0.5cm}

\textbf{Dimensioni del dataset}
\begin{itemize}
    \item \textbf{6599} istanze totali (N-to-N)
    \item \textbf{1885} istanze con doppia annotazione
\end{itemize}

\end{frame}

\section{Training e Test set}

\begin{frame}{Near Minimal Pairs e Distrattori}

\begin{block}{NtoN distractors}
Oltre alle reali istanze della costruzione NtoN, il corpus contiene anche
pattern superficiali \textbf{Noun + to + Noun} che non sono costruzioni NtoN.
Derivano da contesti sintattici diversi (es. verbi che reggono un oggetto
e una PP con \emph{to}): \emph{stick plastic to plastic}, \emph{time to time travel}, ecc.

Questi casi non esprimono il significato della costruzione ma forniscono utili \textbf{esempi negativi} per testare se il modello.
\end{block}

\begin{block}{Near minimal pairs}
Poiché condividono la stessa forma superficiale dei veri NtoN,
questi distrattori costituiscono \textbf{near minimal pairs}:
frasi grammaticali, naturali, quasi identiche in superficie,
ma con \textbf{struttura e significato diversi}.
\end{block}

\begin{block}{Dataset}
Nel case study \textbf{456} near minimal pairs
come distrattori dal corpus.
\end{block}

\end{frame}

\begin{frame}{Split training test set}
\begin{block}{Evitare overfitting}
Max 20 occorrenze per lemma per evitare overfitting e ridurre la sproporzione tra lemmi altamente frequenti e lemmi rari.
\end{block}

\begin{block}{Controllo della generalizzazione}
Generazione split casuali di train/test basati sul lemma del nome presente nella costruzione NtoN, in modo che nessun lemma compaia sia nel training set sia nel test set.
\end{block}


\begin{block}{Bilancimento training}
Poiché il numero di distrattori è significativamente inferiore rispetto alle istanze della costruzione, per bilanciare le categorie nel training set è stato utilizzato l’80\% dei distrattori, abbinato allo stesso numero di costruzioni. Il test set è quindi composto dal restante 20\% dei distrattori, insieme a tutte le costruzioni eccedenti quelle usate per il training.
\end{block}

\end{frame}


\section{BERT, modello di encoder}

\begin{frame}{Embedding e trasformazioni del testo}

\begin{block}{Embedding}
Le parole e le frasi vengono trasformate in \textbf{vettori numerici} chiamati embedding. 
Questi vettori catturano somiglianze semantiche e relazioni tra parole, permettendo al modello di “comprendere” il testo.
\end{block}

\begin{block}{Perché trasformare il testo}
Il testo deve diventare numerico per essere elaborato dai modelli. 
Trasformare significa codificare ogni parola in uno spazio continuo dove vicinanza = somiglianza.
\end{block}

\end{frame}

\begin{frame}{Transformer e Encoder}

\begin{block}{Transformer}
Modello basato su \textbf{self-attention}: ogni parola osserva tutte le altre per capire il contesto. 
Non usa ricorrenza e permette di gestire sequenze lunghe in parallelo.
\end{block}

\begin{block}{Encoder}
L’encoder produce rappresentazioni contestuali di ogni parola, che riflettono sia il significato intrinseco sia le relazioni con le altre parole nel testo.
\end{block}

\end{frame}

\begin{frame}{BERT: bidirezionale e contestuale}

\begin{block}{Cos'è BERT}
BERT è un Transformer \textbf{solo encoder}, che legge il contesto a sinistra e a destra di ogni parola.
Produce embedding contestuali che catturano significato, struttura sintattica e relazioni tra parole.
\end{block}

\begin{block}{Addestramento}
- \textbf{Masked Language Modeling}: predire token mascherati.\\
- \textbf{Next Sentence Prediction}: capire se due frasi sono in sequenza.
\end{block}

\begin{block}{Perché usarlo}
Le rappresentazioni di BERT possono essere adattate a molti task NLP: classificazione, NER, question answering. 
Per questo caso studio, mostrano come la semantica delle costruzioni è rappresentata.
\end{block}

\end{frame}

\section{Task 1: Identificazione}

\begin{frame}{Task 1: Identificazione}
  \begin{block}{Definizione del task}
  Distinguere le istanze autentiche della costruzione NtoN dagli esempi autentici del corrispondente pattern distrattore.
  \end{block}
\end{frame}

\begin{frame}{Base-line}
  \begin{block}{Control classifier}
Le etichette vengono randomizzate e assegnate in modo deterministico al word type.

Le performance dovrebbero attestrarsi near chance.
  \end{block}
  \begin{block}{Non-contextual baseline (GloVe)}
Valuta la performance basata solo su informazioni lessicali, senza contesto.

Dovrebbero attndersi, in virtù dei campi semnatici ricorrenti nella costruzione NtoN come espressioni temporali e parti del corpo, performance non trascurabili.
  \end{block}
\end{frame}

\begin{frame}{A cosa serve la baseline?}
  \begin{block}{Control classifier}
Informa sullla bontà del classificatore
  \end{block}
  \begin{block}{Non-contextual baseline (GloVe)}
  Tutto ciò che supera questa performance potrebbe essere attribuito alle informazioni aggiuntive catturate da BERT attraverso il
  significato contestuale.
  \end{block}
\end{frame}

\section{Task 2: Identificazione (perturbando l'ordine delle parole)}

\begin{frame}{Paper S}
  \begin{block}{Esempio di blocco}
    Testo del blocco esplicativo.
  \end{block}
\end{frame}

\section{Task 3: Disambiguazione semantica}

\begin{frame}{Paper S}
  \begin{block}{Esempio di blocco}
    Testo del blocco esplicativo.
  \end{block}
\end{frame}

\end{document}
