{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0423e11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Costruire l'esperimento\n",
    "\n",
    "Corso di Semantica a.a. 2025/2026\n",
    "\n",
    "18-25 Novembre 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cfd8b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Obiettivo della presentazione\n",
    "\n",
    "- Ricostruire la pipeline di ricerca di Scivetti \\& Schneider\n",
    "- consultare il loro codice e identificare i punti salienti della pipeline\n",
    "- riprodurre i risultati\n",
    "- definire i punti critici nell'ottica di integrare dati sull'italiano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393668f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Il paper\n",
    "\n",
    "[Link](https://aclanthology.org/2025.conll-1.24/)\n",
    "\n",
    "- Paper + Software\n",
    "\n",
    "![image](images/paper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b1bc8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Introduction\n",
    "- The NPN Construction\n",
    "- **Dataset**\n",
    "  - **Corpus Gathering and Cleaning**\n",
    "  - Near Minimal Pairs\n",
    "  - **Train/Test Split**\n",
    "- **Experiment 1: Constructions vs. Distractors**\n",
    "  - **Methodology**\n",
    "  - Results\n",
    "- **Experiment 2: Perturbing Word Order**\n",
    "  - Results\n",
    "  - Analysis\n",
    "- **Experiment 3: Semantic Disambiguation**\n",
    "  - NtoN Subtypes\n",
    "  - **Methodology**\n",
    "  - Results\n",
    "- Related Work\n",
    "- Conclusion\n",
    "- Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b3e28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La pipeline\n",
    "\n",
    "Creare un dataset \n",
    "\n",
    "**>>>**\n",
    "\n",
    "Annotare il dataset\n",
    "\n",
    "**>>>**\n",
    "\n",
    "Estrarre da BERT i vettori contestuali\n",
    "\n",
    "**>>>**\n",
    "\n",
    "Allenare un classificatore su una porzione di dataset\n",
    "\n",
    "**>>>**\n",
    "\n",
    "Testare il classificatore su una porzione diversa di dati\n",
    "\n",
    "**>>>**\n",
    "\n",
    "Analizzare gli errori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7fa84",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cosa ci aspettiamo?\n",
    "\n",
    "- Dataset\n",
    "  - In che formato?\n",
    "  - Quali informazioni?\n",
    "- Vettori\n",
    "  - Che tipo di file?\n",
    "  - Quanti vettori?\n",
    "- Classificatore\n",
    "  - Input? Output?\n",
    "- Predizioni\n",
    "  - In che formato?\n",
    "  - Come valutiamo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed3618",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Dataset\n",
    "\n",
    "<div>\n",
    "<img src=\"images/dataset1.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333384e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### (3.1) Corpus Gathering and Cleaning\n",
    "\n",
    "> First, we use a simple **pattern matching** query to extract instances of the sequence \n",
    "Noun + “to” + Noun from COCA. We extract the examples from the corpus in a **fixed window of \n",
    "+/- 50 tokens from the construction**\n",
    "\n",
    "> then used Stanza (Qi et al., 2020) to **segment the results into sentences** and extract the sentences which contained NtoNs.\n",
    "\n",
    "> We automatically **exclude sentences which contained “from”** preceding the construction\n",
    "\n",
    "> we then manually clean the data, removing sentences that were either **too short (<5 tokens)** or \n",
    "contained **too many typos**\n",
    "\n",
    "> We **annotate** all instances of the construction for their semantic subtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c365c61",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"images/dataset2.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68405c9e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### (3.3) Train/Test Split\n",
    "\n",
    "> we artificially shrink the dataset by **randomly sampling 20 sentences** for each noun lemma \n",
    "which occurs more than 20 times\n",
    "\n",
    "> we generate **random train/test splits based on lemma of the noun** in the NtoN, meaning\n",
    "that there are no lemmas that are seen in both the training set and the testing set.\n",
    "\n",
    "> We take **80 percent of the NtoN distractor patterns for training and withhold twenty percent**. \n",
    "We take a **similar number of NtoN constructions** for training and then test on the remainder, \n",
    "ensuring **training sets are balanced between constructions and distractors**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12217ed1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment 1:\n",
    "\n",
    "> We probe the ability for BERT to distinguish natural instances of the NtoN construction from natural\n",
    "examples of the NtoN distractor pattern\n",
    "\n",
    ">  providing two baseline systems which give perspective on performance based on lexical cues: \n",
    "a control classifier and a non-contextual baseline based on GloVe embeddings\n",
    "\n",
    "> we train a separate probe based on embeddings from each layer of BERT and track\n",
    "performance across layers. We use the BERT-base-cased model, available through the Huggingface\n",
    "transformers library, and choose logistic regression as our linear classification architecture\n",
    "\n",
    "> For all experiments and data settings, we run probes with 5 random seeds and report the\n",
    "average results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99596b12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"images/exp1.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d628e3c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Esperimento 2\n",
    "\n",
    "> we manipulate the test set of the probe by creating 4 perturbed orderings\n",
    "of each test example sentence: PNN, PN, NNP, NP. \n",
    "\n",
    "> Crucially, we do not retrain the linear probe on this perturbed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aea265",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"images/exp2.png\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f180eb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Esperimento 3\n",
    "\n",
    "> we train a classifier to distinguish semantic subtypes of NtoN. [...] We also \n",
    "include examples of the NtoN distractor patterns which are not examples of the construction.\n",
    "\n",
    "> we train control classifiers with a random label assigned to each lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ae94b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"images/exp3.png\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb8fae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La pipeline -- dopo aver letto il paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c01eed",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Selezionare contesti dal COCA \n",
    "\n",
    "**>>>** \n",
    "\n",
    "Segmentare in frasi \n",
    "\n",
    "**>>>** \n",
    "\n",
    "Filtrare frasi per tenere solo istanze con NtoN, non precedute da `from`, lunghe almeno 5 token \n",
    "\n",
    "**>>>** \n",
    "\n",
    "Annotare (più di un annotatore) ogni istanza del dataset come `distractor` o uno dei tipi semantici della costruzione \n",
    "\n",
    "**>>>** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db875616",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Per ogni elemento del dataset, estrarre da BERT-base-cased 12 vettori corrispondenti alla testa\n",
    "della costruzione (preposizione) più un vettore di GloVe (corrispondente al lemma del NOUN) \n",
    "\n",
    "**>>>** \n",
    "\n",
    "Per 5 volte, scegliere una porzione casuale di dataset:\n",
    "\t- allenare un classificatore lineare sui vettori GloVe\n",
    "\t- per ogni layer di BERT, allenare un classificatore lineare\n",
    "\n",
    "**>>>** \n",
    "\n",
    "Calcolare la media dell'accuratezza per ogni tipo di embedding\n",
    "\n",
    "**>>>** \n",
    "\n",
    "Plottare i risultati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d77a19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cosa serve?\n",
    "\n",
    "| Step                                                                                            | Tools                                                                                                                                                  | Input                                                                                                                    | Output                                                                                                                                                                            |\n",
    "| ----------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Selezionare contesti dal COCA                                                                   | script Python per leggere il file riga per riga, espressione regolare per individuare il pattern                                                       | COCA                                                                                                                     | Una serie di righe `tok tok tok... tok N to N tok tok tok ... tok`                                                                                                                |\n",
    "| Segmentare in frasi                                                                             | Stanza                                                                                                                                                 | Una serie di righe `tok tok tok... tok N to N tok tok tok ... tok`                                                       | Una serie di frasi `contesto sinistro - NtoN - contesto destro`                                                                                                                   |\n",
    "| Filtrare frasi per tenere solo istanze con NtoN, non precedute da `from`, lunghe almeno 5 token | Script in Python per controllare che (i) il contesto sinistro non finisca per `from`, (ii) la lunghezza dell'intera frase sia almeno 5 (compreso NtoN) | Una serie di frasi `contesto sinistro - NtoN - contesto destro`                                                          | Una serie di frasi `tok_sx_1 ... tok_sx_n - NtoN - tok_dx_1 ... tok_dx_m`,  con `tok_sx_n` diverso da `from` e `n+m > 1`                                                          |\n",
    "| Annotare ogni istanza del dataset come `distractor` o uno dei tipi semantici della costruzione  | Guidelines per l'annotazione, Excel o software simile                                                                                                  | Una serie di frasi `tok_sx_1 ... tok_sx_n - NtoN - tok_dx_1 ... tok_dx_m`,  con `tok_sx_n` diverso da `from` e `n+m > 1` | Per ogni frase di input, un valore che codifica se l'item è un distractor, o la classe semantica della costruzione, o se la frase è da eliminare, e il lemma del nome costruzione |\n",
    "| estrarre da BERT-base-cased 12 vettori corrispondenti alla testa della costruzione              | Libreria HuggingFace                                                                                                                                   | Dataset annotato                                                                                                         | 12 file (uno per layer di bert) contenente la lista di vettori contestualizzati                                                                                                   |\n",
    "| estrarre il vettore di GloVe (corrispondente al lemma del NOUN)                                 | Script per leggere il formato di GloVe                                                                                                                 | Dataset                                                                                                                  | file contenente i vettori di GloVe per i lemmi presenti nel dataset                                                                                                               |\n",
    "| Sampling dei lemmi troppo presenti                                                              |                                                                                                                                                        |                                                                                                                          |                                                                                                                                                                                   |\n",
    "| Divisione tra train e test                                                                      |                                                                                                                                                        |                                                                                                                          |                                                                                                                                                                                   |\n",
    "| Training del classificatore (regressione lineare)                                               |                                                                                                                                                        |                                                                                                                          |                                                                                                                                                                                   |\n",
    "| Calcolo media delle run                                                                         |                                                                                                                                                        |                                                                                                                          |                                                                                                                                                                                   |\n",
    "| Plot dei risultati                                                                              | Matplotlib                                                                                                                                             |                                                                                                                          |                                                                                                                                                                                   |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
